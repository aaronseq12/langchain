{
 "cells": [
  {
   "cell_type": "raw",
   "id": "018f3868-e60d-4db6-a1c6-c6633c66b1f4",
   "metadata": {},
   "source": [
    "---\n",
    "keywords: [agents, fallbacks, create_agent, middleware_agent, reliability]\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c9cbd6",
   "metadata": {},
   "source": [
    "# How to use fallbacks with create_agent for reliable AI agents\n",
    "\n",
    "When building production AI agents, API failures and outages are inevitable. The `create_agent` function from LangChain's middleware_agent module supports fallback models to ensure your agents remain operational even when primary LLM providers experience downtime.\n",
    "\n",
    "This guide demonstrates how to configure robust agents with automatic failover capabilities using the `create_agent` function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6bb9ba9",
   "metadata": {},
   "source": [
    "## Why Use Fallbacks with Agents?\n",
    "\n",
    "LLM API failures can occur due to:\n",
    "- Rate limiting\n",
    "- Service outages\n",
    "- Network issues\n",
    "- Regional availability problems\n",
    "\n",
    "By configuring fallback models, your agents can automatically switch to backup providers, ensuring continuous operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a449a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade --quiet langchain langchain-openai langchain-anthropic langgraph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "basic-setup",
   "metadata": {},
   "source": [
    "## Basic Fallback Configuration\n",
    "\n",
    "The key to using fallbacks with `create_agent` is configuring your model chain **before** passing it to the agent creator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "basic-example",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.middleware_agent import create_agent\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "# Define a simple tool\n",
    "@tool\n",
    "def get_weather(location: str) -> str:\n",
    "    \"\"\"Get the current weather for a location.\"\"\"\n",
    "    return f\"The weather in {location} is sunny and 75°F\"\n",
    "\n",
    "# Configure models with fallback chain\n",
    "primary_model = ChatOpenAI(model=\"gpt-4o\", max_retries=0)\n",
    "fallback_model = ChatAnthropic(model=\"claude-3-haiku-20240307\")\n",
    "\n",
    "# Create model with fallback support\n",
    "model_with_fallback = primary_model.with_fallbacks([fallback_model])\n",
    "\n",
    "# create_agent accepts the fallback-enabled model seamlessly\n",
    "agent = create_agent(\n",
    "    model=model_with_fallback,\n",
    "    tools=[get_weather],\n",
    "    system_prompt=\"You are a helpful weather assistant with automatic failover capabilities.\"\n",
    ").compile()\n",
    "\n",
    "print(\"Agent created successfully with fallback support!\")\n",
    "\n",
    "# Test the agent\n",
    "result = agent.invoke({\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"What's the weather like in Paris?\"}]\n",
    "})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "best-practices",
   "metadata": {},
   "source": [
    "## Best Practices for Agent Fallbacks\n",
    "\n",
    "### 1. Disable Model-Level Retries\n",
    "\n",
    "When using fallbacks, disable retries on individual models to ensure faster failover:\n",
    "\n",
    "```python\n",
    "# ✅ Good: Fast failover\n",
    "primary_model = ChatOpenAI(model=\"gpt-4o\", max_retries=0)\n",
    "\n",
    "# ❌ Avoid: Slow failover due to retries\n",
    "primary_model = ChatOpenAI(model=\"gpt-4o\", max_retries=3)\n",
    "```\n",
    "\n",
    "### 2. Order Models by Performance and Cost\n",
    "\n",
    "Place your preferred models first:\n",
    "\n",
    "```python\n",
    "# ✅ Good: Best model first, then cheaper alternatives\n",
    "model = ChatOpenAI(\"gpt-4o\").with_fallbacks([\n",
    "    ChatOpenAI(\"gpt-4o-mini\"),  # Cheaper OpenAI\n",
    "    ChatAnthropic(\"claude-3-haiku-20240307\")  # Alternative provider\n",
    "])\n",
    "```\n",
    "\n",
    "### 3. Test Fallback Scenarios\n",
    "\n",
    "Regularly test your fallback configurations to ensure they work when needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusion",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "The `create_agent` function provides excellent support for fallback models, enabling you to build robust AI agents that can withstand API failures and service interruptions.\n",
    "\n",
    "**Key Takeaways:**\n",
    "\n",
    "1. **✅ `create_agent` DOES support fallbacks** - just configure your model chain before passing it\n",
    "2. **Configure fallbacks at the model level** using the `.with_fallbacks()` method\n",
    "3. **Disable model-level retries** for faster failover with `max_retries=0`\n",
    "4. **Order fallbacks strategically** from preferred to backup models\n",
    "5. **Test your fallback scenarios** to ensure reliability\n",
    "\n",
    "This approach provides the same reliability benefits as manual fallback implementations while leveraging LangChain's built-in fallback system for cleaner, more maintainable code.\n",
    "\n",
    "For more information on fallbacks, see the [general fallbacks guide](fallbacks.ipynb)."
   ]
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5
}